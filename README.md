# LLMProxy

é¢å‘å¤§æ¨¡å‹æœåŠ¡çš„é«˜æ€§èƒ½ç½‘å…³ï¼Œæ”¯æŒæµå¼/éæµå¼æ— ç¼ä»£ç† + å¼‚æ­¥ç”¨é‡è®¡é‡ï¼ˆHTTP Webhookï¼‰ã€‚

ä¸­æ–‡æ–‡æ¡£ | [English](README_EN.md)

[![Docker Build](https://github.com/aiyuekuang/LLMProxy/actions/workflows/release.yml/badge.svg)](https://github.com/aiyuekuang/LLMProxy/actions/workflows/release.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Go Version](https://img.shields.io/github/go-mod/go-version/aiyuekuang/LLMProxy)](go.mod)
[![GitHub Stars](https://img.shields.io/github/stars/aiyuekuang/LLMProxy?style=social)](https://github.com/aiyuekuang/LLMProxy/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/aiyuekuang/LLMProxy?style=social)](https://github.com/aiyuekuang/LLMProxy/network/members)

## æ ¸å¿ƒç‰¹æ€§

- âœ… **LLM åè®®æ„ŸçŸ¥ä»£ç†** - è‡ªåŠ¨è¯†åˆ« `/v1/chat/completions` è¯·æ±‚ä¸­çš„ `stream=true/false`
- âœ… **é›¶ç¼“å†²æµå¼ä¼ è¾“** - SSE å“åº”é€ token è½¬å‘ï¼Œä¸å¢åŠ é¦– token å»¶è¿Ÿï¼ˆTTFTï¼‰
- âœ… **å¤šåç«¯è´Ÿè½½å‡è¡¡** - æ”¯æŒ vLLMã€TGIã€è‡ªç ”æœåŠ¡ç­‰ OpenAI å…¼å®¹åç«¯
- âœ… **å¼‚æ­¥ç”¨é‡è®¡é‡** - è¯·æ±‚ç»“æŸåï¼Œåå°å¼‚æ­¥ä¸ŠæŠ¥ `prompt_tokens` + `completion_tokens`
- âœ… **é›¶æ€§èƒ½ä¾µå…¥** - ä¸»è¯·æ±‚è·¯å¾„ä¸è§£æå“åº”ä½“ã€ä¸è¿æ¥æ•°æ®åº“ã€ä¸è°ƒç”¨å¤–éƒ¨æœåŠ¡
- âœ… **æç®€ä¸šåŠ¡å¯¹æ¥** - é€šè¿‡ HTTP Webhook å°†ç”¨é‡æ•°æ®æ¨é€ç»™ä¸šåŠ¡ç³»ç»Ÿ

## å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šä½¿ç”¨å®˜æ–¹é•œåƒï¼ˆæ¨èï¼‰

```bash
# 1. åˆ›å»ºé…ç½®æ–‡ä»¶
curl -o config.yaml https://raw.githubusercontent.com/aiyuekuang/LLMProxy/main/config.yaml.example

# 2. ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹åç«¯åœ°å€
vim config.yaml

# 3. è¿è¡Œå®¹å™¨
docker run -d \
  --name llmproxy \
  -p 8000:8000 \
  -v $(pwd)/config.yaml:/home/llmproxy/config.yaml \
  ghcr.io/aiyuekuang/llmproxy:latest
```

**æ”¯æŒæ¶æ„ï¼š** `linux/amd64`, `linux/arm64`

### æ–¹å¼äºŒï¼šæœ¬åœ°æ„å»º

```bash
# ä¸‹è½½ä¾èµ–
go mod download

# å¤åˆ¶é…ç½®æ–‡ä»¶
cp config.yaml.example config.yaml

# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹åç«¯åœ°å€
vim config.yaml

# è¿è¡Œ
go run cmd/main.go --config config.yaml
```

### æ–¹å¼ä¸‰ï¼šDocker Composeï¼ˆå« vLLMï¼‰

```bash
cd deployments
docker compose up -d
```

è®¿é—®ï¼š
- LLMProxy: http://localhost:8000
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000 (admin/admin)

## é…ç½®è¯´æ˜

```yaml
# ç›‘å¬åœ°å€
listen: ":8000"

# åç«¯æœåŠ¡å™¨åˆ—è¡¨
backends:
  - url: "http://vllm:8000"
    weight: 5
  - url: "http://tgi:8081"
    weight: 3

# ç”¨é‡ä¸ŠæŠ¥ Webhook é…ç½®
usage_hook:
  enabled: true
  url: "https://your-billing.com/llm-usage"
  timeout: 1s
  retry: 2

# å¥åº·æ£€æŸ¥é…ç½®
health_check:
  interval: 10s
  path: /health
```

## åç«¯é…ç½®è¦æ±‚

### vLLM

**å¿…é¡»å¯ç”¨ `--return-detailed-tokens` å‚æ•°ï¼š**

```bash
python -m vllm.entrypoints.openai.api_server \
  --model meta-llama/Llama-3-8b-Instruct \
  --return-detailed-tokens \
  --port 8000
```

### TGI

é»˜è®¤æ”¯æŒï¼Œæ— éœ€é¢å¤–é…ç½®ã€‚

## Webhook æ•°æ®æ ¼å¼

LLMProxy ä¼šå‘é…ç½®çš„ Webhook URL å‘é€ POST è¯·æ±‚ï¼š

```json
{
  "request_id": "req_abc123",
  "user_id": "user_alice",
  "api_key": "sk-prod-xxx",
  "model": "meta-llama/Llama-3-8b",
  "prompt_tokens": 15,
  "completion_tokens": 42,
  "total_tokens": 57,
  "is_stream": true,
  "endpoint": "/v1/chat/completions",
  "timestamp": "2026-01-14T10:30:00Z",
  "backend_url": "http://vllm:8000"
}
```

### ä¸šåŠ¡ç³»ç»Ÿæ¥æ”¶ç¤ºä¾‹ï¼ˆPython Flaskï¼‰

```python
@app.route('/llm-usage', methods=['POST'])
def record_usage():
    data = request.json
    # å†™å…¥æ•°æ®åº“
    db.execute(
        "INSERT INTO billing_events (customer, input_tk, output_tk, model) VALUES (?, ?, ?, ?)",
        data['user_id'], data['prompt_tokens'], data['completion_tokens'], data['model']
    )
    return {"status": "ok"}
```

## ç›‘æ§æŒ‡æ ‡

LLMProxy æš´éœ² Prometheus æŒ‡æ ‡ï¼ˆ`/metrics`ï¼‰ï¼š

| æŒ‡æ ‡åç§° | ç±»å‹ | è¯´æ˜ |
|---------|------|------|
| `llmproxy_requests_total` | Counter | è¯·æ±‚æ€»æ•°ï¼ˆæ ‡ç­¾ï¼špath, stream, backend, statusï¼‰ |
| `llmproxy_latency_ms` | Histogram | è¯·æ±‚å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ |
| `llmproxy_webhook_success_total` | Counter | Webhook æˆåŠŸæ•° |
| `llmproxy_webhook_failure_total` | Counter | Webhook å¤±è´¥æ•° |
| `llmproxy_usage_tokens_total` | Counter | Token ä½¿ç”¨é‡ï¼ˆæ ‡ç­¾ï¼štype=prompt/completionï¼‰ |

## API ä½¿ç”¨ç¤ºä¾‹

### éæµå¼è¯·æ±‚

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama/Llama-3-8b-Instruct",
    "messages": [{"role": "user", "content": "Hello"}],
    "stream": false
  }'
```

### æµå¼è¯·æ±‚

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama/Llama-3-8b-Instruct",
    "messages": [{"role": "user", "content": "Hello"}],
    "stream": true
  }'
```

## æ¶æ„è®¾è®¡

```
+------------------+
|     Client       | â† curl / SDK
+--------+---------+
         |
         | POST /v1/chat/completions { "stream": true, ... }
         v
+--------+---------+
|    LLMProxy      | â† Go æœåŠ¡ï¼ˆå•äºŒè¿›åˆ¶ï¼‰
|  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” |
|  â”‚  Router     â”‚ |â†â”€â”€ ä»…è·¯ç”± LLM API è·¯å¾„
|  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ |
|  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” |
|  â”‚LoadBalancer â”‚ |â†â”€â”€ è½®è¯¢/æƒé‡/æœ€å°‘è¿æ¥
|  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ |
|  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” |
|  â”‚ProxyEngine  â”‚ |â†â”€â”€ æ ¸å¿ƒï¼šé€ä¼ è¯·æ±‚/å“åº”ï¼ˆæ— ç¼“å†²ï¼ï¼‰
|  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ |
|  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” |
|  â”‚ UsageHook   â”‚ |â†â”€â”€ è¯·æ±‚ç»“æŸåï¼Œå¯åŠ¨åå° goroutine
|  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ |
+--------+---------+
         |         | (async)
         |         v
         |  [HTTP Webhook] â”€â”€â”€â”€â†’ https://your-billing.com/usage
         v
+------------------+     +------------------+
|   vLLM (8000)    |     |   TGI (8081)     |
|   + usage        |     |   + usage        |
+------------------+     +------------------+
```

## æ€§èƒ½ç‰¹ç‚¹

- **é›¶ç¼“å†²æµå¼ä¼ è¾“**ï¼šä½¿ç”¨ `io.Copy` å®ç°å†…æ ¸çº§ spliceï¼ŒCPU å¼€é”€æä½
- **å¼‚æ­¥ç”¨é‡ä¸ŠæŠ¥**ï¼šåœ¨ goroutine ä¸­æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»è¯·æ±‚
- **è¿æ¥å¤ç”¨**ï¼šHTTP å®¢æˆ·ç«¯å¤ç”¨è¿æ¥ï¼Œå‡å°‘æ¡æ‰‹å¼€é”€
- **å¥åº·æ£€æŸ¥**ï¼šè‡ªåŠ¨æ‘˜é™¤ä¸å¥åº·èŠ‚ç‚¹ï¼Œæé«˜å¯ç”¨æ€§

## é¡¹ç›®ç»“æ„

```
llmproxy/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go                 # å…¥å£
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ config/                 # é…ç½®è§£æ
â”‚   â”‚   â””â”€â”€ config.go
â”‚   â”œâ”€â”€ proxy/                  # æ ¸å¿ƒä»£ç†å¼•æ“
â”‚   â”‚   â”œâ”€â”€ handler.go          # è¯·æ±‚å¤„ç†
â”‚   â”‚   â””â”€â”€ usage_hook.go       # Webhook ä¸ŠæŠ¥
â”‚   â”œâ”€â”€ lb/                     # è´Ÿè½½å‡è¡¡å™¨
â”‚   â”‚   â””â”€â”€ roundrobin.go
â”‚   â””â”€â”€ metrics/                # Prometheus æŒ‡æ ‡
â”‚       â””â”€â”€ metrics.go
â”œâ”€â”€ deployments/
â”‚   â”œâ”€â”€ docker-compose.yml      # æœ¬åœ°æµ‹è¯•
â”‚   â”œâ”€â”€ config.yaml             # Docker é…ç½®
â”‚   â””â”€â”€ prometheus.yml          # Prometheus é…ç½®
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ dashboard.json          # Grafana é¢æ¿
â”œâ”€â”€ config.yaml.example         # é…ç½®ç¤ºä¾‹
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ go.mod
â””â”€â”€ README.md
```

## å¸¸è§é—®é¢˜

### 1. ä¸ºä»€ä¹ˆå“åº”ä¸­æ²¡æœ‰ usage ä¿¡æ¯ï¼Ÿ

ç¡®ä¿åç«¯å¯ç”¨äº† usage è¿”å›ï¼š
- vLLMï¼šæ·»åŠ  `--return-detailed-tokens` å‚æ•°
- TGIï¼šé»˜è®¤æ”¯æŒ

### 2. Webhook å‘é€å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

LLMProxy ä¼šè‡ªåŠ¨é‡è¯•ï¼ˆæ ¹æ®é…ç½®çš„ `retry` æ¬¡æ•°ï¼‰ï¼Œå¤±è´¥ä»…è®°å½•æ—¥å¿—ï¼Œä¸å½±å“ä¸»è¯·æ±‚ã€‚

### 3. å¦‚ä½•æŸ¥çœ‹ç›‘æ§æŒ‡æ ‡ï¼Ÿ

è®¿é—® `http://localhost:8000/metrics` æŸ¥çœ‹ Prometheus æŒ‡æ ‡ã€‚

### 4. æ”¯æŒå“ªäº›è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼Ÿ

å½“å‰æ”¯æŒåŠ æƒè½®è¯¢ï¼ˆWeighted Round Robinï¼‰ï¼Œåç»­å¯æ‰©å±•æœ€å°‘è¿æ¥ç­‰ç­–ç•¥ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) å¼€æºåè®®ã€‚

è¿™æ„å‘³ç€ä½ å¯ä»¥ï¼š
- âœ… è‡ªç”±ä½¿ç”¨ã€ä¿®æ”¹å’Œåˆ†å‘æœ¬è½¯ä»¶
- âœ… ç”¨äºå•†ä¸šé¡¹ç›®
- âœ… åˆ›å»ºè¡ç”Ÿä½œå“

å”¯ä¸€è¦æ±‚ï¼šä¿ç•™åŸå§‹ç‰ˆæƒå£°æ˜å’Œè®¸å¯è¯å£°æ˜ã€‚

## è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼æŸ¥çœ‹ [CONTRIBUTORS.md](CONTRIBUTORS.md) äº†è§£è´¡çŒ®è€…åå•ã€‚

### å¦‚ä½•è´¡çŒ®

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤ä¿®æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

è¯¦ç»†è´¡çŒ®æŒ‡å—è¯·å‚è€ƒ [CONTRIBUTORS.md](CONTRIBUTORS.md)ã€‚

## æ”¯æŒé¡¹ç›®

å¦‚æœ LLMProxy å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ï¼š

- â­ ç»™é¡¹ç›®ç‚¹ä¸ª Star
- ğŸ› æŠ¥å‘Š Bug æˆ–æå‡ºæ”¹è¿›å»ºè®®
- ğŸ“ æ”¹è¿›æ–‡æ¡£æˆ–æ·»åŠ ç¤ºä¾‹
- ğŸ’¬ åœ¨ç¤¾åŒºä¸­åˆ†äº«ä½ çš„ä½¿ç”¨ç»éªŒ
- ğŸ”— åœ¨ä½ çš„é¡¹ç›®ä¸­æ·»åŠ  "Powered by LLMProxy" å¾½ç« ï¼š

```markdown
[![Powered by LLMProxy](https://img.shields.io/badge/Powered%20by-LLMProxy-blue)](https://github.com/aiyuekuang/LLMProxy)
```

## è”ç³»æ–¹å¼

- ğŸ“§ Issues: [GitHub Issues](https://github.com/aiyuekuang/LLMProxy/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/aiyuekuang/LLMProxy/discussions)
