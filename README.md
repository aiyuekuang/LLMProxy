# LLMProxy

**è‡ªå»º LLM æ¨ç†æœåŠ¡çš„é«˜æ€§èƒ½ç½‘å…³** - ä¸º vLLMã€TGIã€è‡ªç ”æ¨ç†å¼•æ“è€Œç”Ÿ

ä¸­æ–‡æ–‡æ¡£ | [English](README_EN.md)

[![Docker Build](https://github.com/aiyuekuang/LLMProxy/actions/workflows/release.yml/badge.svg)](https://github.com/aiyuekuang/LLMProxy/actions/workflows/release.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Go Version](https://img.shields.io/github/go-mod/go-version/aiyuekuang/LLMProxy)](go.mod)
[![GitHub Stars](https://img.shields.io/github/stars/aiyuekuang/LLMProxy?style=social)](https://github.com/aiyuekuang/LLMProxy/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/aiyuekuang/LLMProxy?style=social)](https://github.com/aiyuekuang/LLMProxy/network/members)

## äº§å“å®šä½

LLMProxy ä¸“ä¸º **è‡ªå»ºæ¨ç†æœåŠ¡**ï¼ˆvLLMã€TGIã€è‡ªç ”å¼•æ“ï¼‰è®¾è®¡ï¼Œä¸æ˜¯äº‘ç«¯ API èšåˆå¹³å°ã€‚

**å…¸å‹ä½¿ç”¨åœºæ™¯ï¼š**
- ğŸ¢ ä½¿ç”¨ vLLM/TGI éƒ¨ç½²å¼€æºæ¨¡å‹çš„å›¢é˜Ÿ
- ğŸ”’ ç§æœ‰åŒ–éƒ¨ç½²çš„ä¼ä¸šï¼ˆæ•°æ®ä¸å‡ºå†…ç½‘ï¼‰
- âš¡ å¯¹æ€§èƒ½è¦æ±‚æé«˜çš„å®æ—¶å¯¹è¯åº”ç”¨
- ğŸ¯ éœ€è¦ç®€å•ç®¡ç†å’Œç›‘æ§çš„è‡ªå»ºæœåŠ¡

**ä¸é€‚ç”¨åœºæ™¯ï¼š**
- âŒ éœ€è¦å¯¹æ¥ OpenAI/Claude/Gemini äº‘ç«¯ APIï¼ˆè¯·ä½¿ç”¨ LiteLLM/One-APIï¼‰
- âŒ éœ€è¦å¤æ‚å¤šç§Ÿæˆ·ç®¡ç†çš„ä¼ä¸šå¹³å°

## æ ¸å¿ƒç‰¹æ€§

### ğŸš€ æè‡´æ€§èƒ½
- âœ… **é›¶ç¼“å†²æµå¼ä¼ è¾“** - SSE å“åº”é€ token è½¬å‘ï¼Œä¸å¢åŠ é¦– token å»¶è¿Ÿï¼ˆTTFTï¼‰
- âœ… **é›¶æ€§èƒ½ä¾µå…¥** - ä¸»è¯·æ±‚è·¯å¾„ä¸è§£æå“åº”ä½“ã€ä¸è¿æ¥æ•°æ®åº“ã€ä¸è°ƒç”¨å¤–éƒ¨æœåŠ¡
- âœ… **è¿æ¥å¤ç”¨** - HTTP å®¢æˆ·ç«¯å¤ç”¨è¿æ¥ï¼Œå‡å°‘æ¡æ‰‹å¼€é”€

### ğŸ¯ é€æ˜ä»£ç†
- âœ… **å®Œå…¨é€ä¼ ** - ä¸å…³å¿ƒä¸šåŠ¡å‚æ•°ï¼ˆå¦‚ modelï¼‰ï¼Œå®Œå…¨é€ä¼ æ‰€æœ‰è¯·æ±‚å‚æ•°åˆ°åç«¯
- âœ… **è‡ªåŠ¨é‡è¯•** - æŒ‡æ•°é€€é¿ç­–ç•¥ï¼Œç½‘ç»œæŠ–åŠ¨è‡ªåŠ¨é‡è¯•
- âœ… **å¤šç§è´Ÿè½½å‡è¡¡** - è½®è¯¢ã€æœ€å°‘è¿æ¥æ•°ã€å»¶è¿Ÿä¼˜å…ˆ
- âœ… **çµæ´»è·¯ç”±** - æ”¯æŒé€šè¿‡ Webhook å®ç°è‡ªå®šä¹‰è·¯ç”±é€»è¾‘

### ğŸ” å¯ç¼–æ’é‰´æƒç®¡é“ (v0.3.0 æ–°å¢)
- âœ… **å¤šæ•°æ®æºæ”¯æŒ** - é…ç½®æ–‡ä»¶ / Redis / æ•°æ®åº“ï¼ˆMySQL/PostgreSQL/SQLiteï¼‰/ Webhook
- âœ… **Lua è„šæœ¬å†³ç­–** - è‡ªå®šä¹‰é‰´æƒé€»è¾‘ï¼Œçµæ´»æ§åˆ¶æ”¾è¡Œ/æ‹’ç»
- âœ… **å¯ç¼–æ’é¡ºåº** - è‡ªç”±è°ƒæ•´ Provider æ‰§è¡Œé¡ºåº
- âœ… **ä¸¤ç§ç®¡é“æ¨¡å¼** - `first_match`ï¼ˆé¦–ä¸ªæˆåŠŸå³æ”¾è¡Œï¼‰æˆ– `all`ï¼ˆå…¨éƒ¨é€šè¿‡ï¼‰
- âœ… **è‡ªå®šä¹‰è®¤è¯ Header** - æ”¯æŒé…ç½®ä»»æ„ Header åç§°
- âœ… **IP ç™½åå•** - é˜²æ­¢æœªæˆæƒè®¿é—®
- âœ… **é¢åº¦ç®¡ç†** - Token é…é¢ã€è‡ªåŠ¨é‡ç½®ï¼ˆæŒ‰å¤©/å‘¨/æœˆï¼‰

### ğŸ›¡ï¸ é™æµä¿æŠ¤
- âœ… **å…¨å±€é™æµ** - ä¿æŠ¤æ¨ç†æœåŠ¡ä¸è¢«æ‰“å®
- âœ… **Key çº§é™æµ** - é˜²æ­¢å•ä¸ªç”¨æˆ·æ»¥ç”¨
- âœ… **å¹¶å‘æ§åˆ¶** - é™åˆ¶æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
- âœ… **ä»¤ç‰Œæ¡¶ç®—æ³•** - æ”¯æŒçªå‘æµé‡

### ğŸ“Š ç›‘æ§è®¡é‡
- âœ… **å®Œæ•´è¯·æ±‚é€ä¼ ** - Webhook æ¥æ”¶å®Œæ•´çš„è¯·æ±‚å‚æ•°å’Œå“åº”æ•°æ®
- âœ… **å¼‚æ­¥ç”¨é‡è®¡é‡** - è¯·æ±‚ç»“æŸåï¼Œåå°å¼‚æ­¥ä¸ŠæŠ¥ `prompt_tokens` + `completion_tokens`
- âœ… **Prometheus æŒ‡æ ‡** - è¯·æ±‚é‡ã€å»¶è¿Ÿã€é”™è¯¯ç‡ç­‰
- âœ… **Grafana é¢æ¿** - é¢„é…ç½®ç›‘æ§é¢æ¿
- âœ… **çµæ´»æ‰©å±•** - é€šè¿‡ Webhook å®ç°è‡ªå®šä¹‰ä¸šåŠ¡é€»è¾‘ï¼ˆæƒé™æ§åˆ¶ã€æ¨¡å‹æ˜ å°„ã€è®¡è´¹ç­‰ï¼‰

## çœŸå®ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šAI å®¢æœç³»ç»Ÿï¼ˆå®æ—¶å¯¹è¯ï¼‰

æŸç”µå•†å…¬å¸ä½¿ç”¨ vLLM éƒ¨ç½²äº† Qwen-72B æ¨¡å‹ï¼Œæ—¥å‡ 10 ä¸‡æ¬¡å¯¹è¯ã€‚

**æ¶æ„ï¼š**
```
å®¢æˆ· Web/App â†’ Nginx â†’ LLMProxy â†’ vLLM é›†ç¾¤ï¼ˆ3å° GPUï¼‰
```

**é…ç½®ï¼š**
```yaml
backends:
  - url: "http://gpu-1.internal:8000"
    weight: 10
  - url: "http://gpu-2.internal:8000"
    weight: 10
  - url: "http://gpu-3.internal:8000"
    weight: 10

routing:
  retry:
    enabled: true
    max_retries: 2
  fallback:
    - primary: "http://gpu-1.internal:8000"
      fallback: ["http://gpu-2.internal:8000", "http://gpu-3.internal:8000"]

rate_limit:
  global:
    requests_per_second: 500
```

**æ•ˆæœï¼š**
- å»¶è¿Ÿé™ä½ 40%ï¼ˆä» 800ms é™åˆ° 480msï¼‰
- å¯ç”¨æ€§æå‡åˆ° 99.9%
- GPU åˆ©ç”¨ç‡ä» 60% æå‡åˆ° 85%

---

### åœºæ™¯ 2ï¼šä¼ä¸šå†…éƒ¨ AI åŠ©æ‰‹ï¼ˆç§æœ‰åŒ–éƒ¨ç½²ï¼‰

æŸé‡‘èå…¬å¸ä¸º 1000 åå‘˜å·¥æä¾› AI åŠ©æ‰‹ï¼Œä½¿ç”¨ TGI éƒ¨ç½² Llama-3-70Bã€‚

**æ¶æ„ï¼š**
```
ä¼ä¸šå‘˜å·¥ â†’ ä¼ä¸šå†…ç½‘ â†’ LLMProxy â†’ TGI æœåŠ¡ï¼ˆ2å°ï¼‰
```

**é…ç½®ï¼š**
```yaml
auth:
  enabled: true
  storage: "file"

api_keys:
  - key: "sk-llmproxy-dev-team-001"
    name: "ç ”å‘éƒ¨é—¨"
    total_quota: 500000  # æ¯å¤© 50 ä¸‡ tokens
    allowed_ips: ["10.0.1.0/24"]
  
  - key: "sk-llmproxy-product-team-001"
    name: "äº§å“éƒ¨é—¨"
    total_quota: 200000
    allowed_ips: ["10.0.2.0/24"]

rate_limit:
  per_key:
    requests_per_minute: 100
    max_concurrent: 5
```

**æ•ˆæœï¼š**
- éƒ¨ç½²æ—¶é—´ä» 2 å‘¨ç¼©çŸ­åˆ° 1 å¤©
- æ— éœ€æ•°æ®åº“ï¼Œé…ç½®æ–‡ä»¶ç®¡ç†
- é€šè¿‡å†…éƒ¨å®‰å…¨å®¡è®¡
- å„éƒ¨é—¨ç”¨é‡æ¸…æ™°å¯è§

---

### åœºæ™¯ 3ï¼šæ¨¡å‹æœåŠ¡å•†ï¼ˆå¯¹å¤–æä¾› APIï¼‰

æŸ AI åˆ›ä¸šå…¬å¸ä½¿ç”¨ vLLM éƒ¨ç½²å¤šä¸ªå¼€æºæ¨¡å‹ï¼Œå¯¹å¤–æä¾›æ¨ç† APIã€‚

**æ¶æ„ï¼š**
```
å®¢æˆ·ï¼ˆ100+ å®¶ä¼ä¸šï¼‰â†’ å…¬ç½‘ â†’ LLMProxy â†’ vLLM é›†ç¾¤ï¼ˆå¤šæ¨¡å‹ï¼‰
```

**é…ç½®ï¼š**
```yaml
backends:
  - url: "http://vllm-server-1:8000"
  - url: "http://vllm-server-2:8000"

routing:
  retry:
    enabled: true
    max_retries: 2

auth:
  enabled: true
  storage: "redis"

rate_limit:
  global:
    requests_per_second: 1000
  per_key:
    requests_per_second: 10
    tokens_per_minute: 100000
```

**æ•ˆæœï¼š**
- æœåŠ¡ 100+ å®¶ä¼ä¸šå®¢æˆ·
- æ—¥å‡ 500 ä¸‡æ¬¡è¯·æ±‚
- å¯ç”¨æ€§ 99.95%
- å¹³å‡å»¶è¿Ÿ < 300ms

è¯¦ç»†åœºæ™¯è¯´æ˜è¯·å‚è€ƒï¼š[çœŸå®ä½¿ç”¨åœºæ™¯æ–‡æ¡£](docs/real-world-scenarios.md)

---

## å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šä½¿ç”¨å®˜æ–¹é•œåƒï¼ˆæ¨èï¼‰

```bash
# 1. åˆ›å»ºé…ç½®æ–‡ä»¶
curl -o config.yaml https://raw.githubusercontent.com/aiyuekuang/LLMProxy/main/config.yaml.example

# 2. ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹åç«¯åœ°å€
vim config.yaml

# 3. è¿è¡Œå®¹å™¨
docker run -d \
  --name llmproxy \
  -p 8000:8000 \
  -v $(pwd)/config.yaml:/home/llmproxy/config.yaml \
  ghcr.io/aiyuekuang/llmproxy:latest
```

**æ”¯æŒæ¶æ„ï¼š** `linux/amd64`, `linux/arm64`

### æ–¹å¼äºŒï¼šæœ¬åœ°æ„å»º

```bash
# ä¸‹è½½ä¾èµ–
go mod download

# å¤åˆ¶é…ç½®æ–‡ä»¶
cp config.yaml.example config.yaml

# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹åç«¯åœ°å€
vim config.yaml

# è¿è¡Œ
go run cmd/main.go --config config.yaml
```

### æ–¹å¼ä¸‰ï¼šDocker Composeï¼ˆå« vLLMï¼‰

```bash
cd deployments
docker compose up -d
```

è®¿é—®ï¼š
- LLMProxy: http://localhost:8000
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000 (admin/admin)

## é…ç½®è¯´æ˜

### åŸºç¡€é…ç½®

```yaml
# ç›‘å¬åœ°å€
listen: ":8000"

# åç«¯æœåŠ¡å™¨åˆ—è¡¨
backends:
  - url: "http://vllm:8000"
    weight: 5
  - url: "http://tgi:8081"
    weight: 3

# ç”¨é‡ä¸ŠæŠ¥é…ç½®ï¼ˆæ”¯æŒå¤šä¸ŠæŠ¥å™¨ï¼‰
usage_hook:
  enabled: true
  reporters:
    - name: "billing"
      type: "webhook"
      enabled: true
      url: "https://your-billing.com/llm-usage"
      timeout: 3s
    - name: "database"
      type: "database"
      enabled: true
      database:
        driver: "mysql"
        dsn: "user:pass@tcp(localhost:3306)/llmproxy"
  retry: 2

# å¥åº·æ£€æŸ¥é…ç½®
health_check:
  interval: 10s
  path: /health
```

### è·¯ç”±é…ç½®

```yaml
routing:
  # é‡è¯•é…ç½®
  retry:
    enabled: true
    max_retries: 3
    initial_wait: 1s
    max_wait: 10s
    multiplier: 2.0
  
  # è´Ÿè½½å‡è¡¡ç­–ç•¥
  load_balance_strategy: "least_connections"  # round_robin, least_connections, latency_based
```

### é‰´æƒé…ç½®ï¼ˆv0.3.0 ç®¡é“æ¨¡å¼ï¼‰

```yaml
auth:
  enabled: true
  header_names: ["Authorization", "X-API-Key"]
  mode: "first_match"  # first_match | all
  
  pipeline:
    # 1. Redis éªŒè¯ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
    - name: "redis_auth"
      type: "redis"
      enabled: true
      redis:
        addr: "localhost:6379"
        key_pattern: "llmproxy:key:{api_key}"
      lua_script: |
        if tonumber(data.balance or 0) <= 0 then
          return {allow = false, message = "ä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼"}
        end
        return {allow = true}
    
    # 2. é…ç½®æ–‡ä»¶éªŒè¯ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    - name: "config_file"
      type: "file"
      enabled: true
      lua_script: |
        if data.status ~= "active" then
          return {allow = false, message = "Key å·²ç¦ç”¨"}
        end
        return {allow = true}

# API Keysï¼ˆç”¨äº file providerï¼‰
api_keys:
  - key: "sk-llmproxy-test123"
    name: "æµ‹è¯• Key"
    user_id: "user_001"
    status: "active"
    total_quota: 100000
    quota_reset_period: "daily"
    allowed_ips: ["192.168.1.0/24"]
    expires_at: "2026-12-31T23:59:59Z"
```

### é™æµé…ç½®

```yaml
rate_limit:
  enabled: true
  storage: "redis"  # æˆ– "memory"
  
  # å…¨å±€é™æµ
  global:
    enabled: true
    requests_per_second: 1000
    burst_size: 2000
  
  # API Key çº§é™æµ
  per_key:
    enabled: true
    requests_per_second: 10
    requests_per_minute: 500
    tokens_per_minute: 100000  # TPM é™åˆ¶
    max_concurrent: 5
```

å®Œæ•´é…ç½®ç¤ºä¾‹è¯·å‚è€ƒï¼š[config.yaml.example](config.yaml.example)

## åç«¯é…ç½®è¦æ±‚

### vLLM

**å¿…é¡»å¯ç”¨ `--return-detailed-tokens` å‚æ•°ï¼š**

```bash
python -m vllm.entrypoints.openai.api_server \
  --model meta-llama/Llama-3-8b-Instruct \
  --return-detailed-tokens \
  --port 8000
```

### TGI

é»˜è®¤æ”¯æŒï¼Œæ— éœ€é¢å¤–é…ç½®ã€‚

## Webhook æ•°æ®æ ¼å¼

LLMProxy ä¼šå‘é…ç½®çš„ Webhook URL å‘é€ POST è¯·æ±‚ï¼Œ**å®Œæ•´é€ä¼ ç”¨æˆ·çš„æ‰€æœ‰è¯·æ±‚å‚æ•°**ï¼š

```json
{
  "request_id": "req_abc123",
  "user_id": "user_alice",
  "api_key": "sk-prod-xxx",
  "request_body": {
    "model": "meta-llama/Llama-3-8b",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "temperature": 0.7,
    "max_tokens": 100
  },
  "usage": {
    "prompt_tokens": 15,
    "completion_tokens": 42,
    "total_tokens": 57
  },
  "is_stream": true,
  "endpoint": "/v1/chat/completions",
  "timestamp": "2026-01-14T10:30:00Z",
  "backend_url": "http://vllm:8000",
  "latency_ms": 1234,
  "status_code": 200
}
```

**é€æ˜ä»£ç†è®¾è®¡ç†å¿µï¼š**
- LLMProxy ä¸å…³å¿ƒä¸šåŠ¡å‚æ•°ï¼ˆå¦‚ modelï¼‰ï¼Œå®Œå…¨é€ä¼ æ‰€æœ‰è¯·æ±‚å‚æ•°
- ä¸šåŠ¡é€»è¾‘ï¼ˆæƒé™æ§åˆ¶ã€æ¨¡å‹æ˜ å°„ã€è®¡è´¹ç­‰ï¼‰ç”± Webhook æ¥æ”¶æ–¹å¤„ç†
- è¿™ä½¿å¾— LLMProxy ä¿æŒç®€å•ã€é«˜æ€§èƒ½ï¼ŒåŒæ—¶æä¾›æœ€å¤§çš„çµæ´»æ€§

### ä¸šåŠ¡ç³»ç»Ÿæ¥æ”¶ç¤ºä¾‹ï¼ˆPython Flaskï¼‰

```python
@app.route('/llm-usage', methods=['POST'])
def record_usage():
    data = request.json
    
    # è·å–ç”¨æˆ·è¯·æ±‚çš„å®Œæ•´å‚æ•°
    request_body = data.get('request_body', {})
    model = request_body.get('model', 'unknown')
    
    # è·å–ç”¨é‡ä¿¡æ¯
    usage = data.get('usage', {})
    prompt_tokens = usage.get('prompt_tokens', 0)
    completion_tokens = usage.get('completion_tokens', 0)
    
    # å†™å…¥æ•°æ®åº“
    db.execute(
        "INSERT INTO billing_events (customer, input_tk, output_tk, model) VALUES (?, ?, ?, ?)",
        data['user_id'], prompt_tokens, completion_tokens, model
    )
    
    # å¯ä»¥åœ¨è¿™é‡Œå®ç°è‡ªå®šä¹‰ä¸šåŠ¡é€»è¾‘ï¼š
    # - æ¨¡å‹æƒé™æ£€æŸ¥
    # - è‡ªå®šä¹‰è®¡è´¹è§„åˆ™
    # - æ•°æ®åˆ†æå’Œç»Ÿè®¡
    
    return {"status": "ok"}
```

## ç›‘æ§æŒ‡æ ‡

LLMProxy æš´éœ² Prometheus æŒ‡æ ‡ï¼ˆ`/metrics`ï¼‰ï¼š

| æŒ‡æ ‡åç§° | ç±»å‹ | è¯´æ˜ |
|---------|------|------|
| `llmproxy_requests_total` | Counter | è¯·æ±‚æ€»æ•°ï¼ˆæ ‡ç­¾ï¼špath, stream, backend, statusï¼‰ |
| `llmproxy_latency_ms` | Histogram | è¯·æ±‚å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ |
| `llmproxy_webhook_success_total` | Counter | Webhook æˆåŠŸæ•° |
| `llmproxy_webhook_failure_total` | Counter | Webhook å¤±è´¥æ•° |
| `llmproxy_usage_tokens_total` | Counter | Token ä½¿ç”¨é‡ï¼ˆæ ‡ç­¾ï¼štype=prompt/completionï¼‰ |

## API ä½¿ç”¨ç¤ºä¾‹

### éæµå¼è¯·æ±‚

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama/Llama-3-8b-Instruct",
    "messages": [{"role": "user", "content": "Hello"}],
    "stream": false
  }'
```

### æµå¼è¯·æ±‚

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama/Llama-3-8b-Instruct",
    "messages": [{"role": "user", "content": "Hello"}],
    "stream": true
  }'
```

## æ¶æ„è®¾è®¡

```
+------------------+
|     Client       | â† curl / SDK
+--------+---------+
         |
         | POST /v1/chat/completions { "stream": true, ... }
         v
+--------+---------+
|    LLMProxy      | â† Go æœåŠ¡ï¼ˆå•äºŒè¿›åˆ¶ï¼‰
|  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” |
|  â”‚  Router     â”‚ |â†â”€â”€ ä»…è·¯ç”± LLM API è·¯å¾„
|  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ |
|  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” |
|  â”‚LoadBalancer â”‚ |â†â”€â”€ è½®è¯¢/æƒé‡/æœ€å°‘è¿æ¥
|  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ |
|  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” |
|  â”‚ProxyEngine  â”‚ |â†â”€â”€ æ ¸å¿ƒï¼šé€ä¼ è¯·æ±‚/å“åº”ï¼ˆæ— ç¼“å†²ï¼ï¼‰
|  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ |
|  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” |
|  â”‚ UsageHook   â”‚ |â†â”€â”€ è¯·æ±‚ç»“æŸåï¼Œå¯åŠ¨åå° goroutine
|  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ |
+--------+---------+
         |         | (async)
         |         v
         |  [HTTP Webhook] â”€â”€â”€â”€â†’ https://your-billing.com/usage
         v
+------------------+     +------------------+
|   vLLM (8000)    |     |   TGI (8081)     |
|   + usage        |     |   + usage        |
+------------------+     +------------------+
```

## æ€§èƒ½ç‰¹ç‚¹

- **é›¶ç¼“å†²æµå¼ä¼ è¾“**ï¼šä½¿ç”¨ `io.Copy` å®ç°å†…æ ¸çº§ spliceï¼ŒCPU å¼€é”€æä½
- **å¼‚æ­¥ç”¨é‡ä¸ŠæŠ¥**ï¼šåœ¨ goroutine ä¸­æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»è¯·æ±‚
- **è¿æ¥å¤ç”¨**ï¼šHTTP å®¢æˆ·ç«¯å¤ç”¨è¿æ¥ï¼Œå‡å°‘æ¡æ‰‹å¼€é”€
- **å¥åº·æ£€æŸ¥**ï¼šè‡ªåŠ¨æ‘˜é™¤ä¸å¥åº·èŠ‚ç‚¹ï¼Œæé«˜å¯ç”¨æ€§

## é¡¹ç›®ç»“æ„

```
llmproxy/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go                 # å…¥å£
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ config/                 # é…ç½®è§£æ
â”‚   â”‚   â””â”€â”€ config.go
â”‚   â”œâ”€â”€ proxy/                  # æ ¸å¿ƒä»£ç†å¼•æ“
â”‚   â”‚   â”œâ”€â”€ handler.go          # è¯·æ±‚å¤„ç†
â”‚   â”‚   â””â”€â”€ usage_hook.go       # Webhook ä¸ŠæŠ¥
â”‚   â”œâ”€â”€ lb/                     # è´Ÿè½½å‡è¡¡å™¨
â”‚   â”‚   â””â”€â”€ roundrobin.go
â”‚   â””â”€â”€ metrics/                # Prometheus æŒ‡æ ‡
â”‚       â””â”€â”€ metrics.go
â”œâ”€â”€ deployments/
â”‚   â”œâ”€â”€ docker-compose.yml      # æœ¬åœ°æµ‹è¯•
â”‚   â”œâ”€â”€ config.yaml             # Docker é…ç½®
â”‚   â””â”€â”€ prometheus.yml          # Prometheus é…ç½®
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ dashboard.json          # Grafana é¢æ¿
â”œâ”€â”€ config.yaml.example         # é…ç½®ç¤ºä¾‹
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ go.mod
â””â”€â”€ README.md
```

## å¸¸è§é—®é¢˜

### 1. ä¸ºä»€ä¹ˆå“åº”ä¸­æ²¡æœ‰ usage ä¿¡æ¯ï¼Ÿ

ç¡®ä¿åç«¯å¯ç”¨äº† usage è¿”å›ï¼š
- vLLMï¼šæ·»åŠ  `--return-detailed-tokens` å‚æ•°
- TGIï¼šé»˜è®¤æ”¯æŒ

### 2. Webhook å‘é€å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

LLMProxy ä¼šè‡ªåŠ¨é‡è¯•ï¼ˆæ ¹æ®é…ç½®çš„ `retry` æ¬¡æ•°ï¼‰ï¼Œå¤±è´¥ä»…è®°å½•æ—¥å¿—ï¼Œä¸å½±å“ä¸»è¯·æ±‚ã€‚

### 3. å¦‚ä½•æŸ¥çœ‹ç›‘æ§æŒ‡æ ‡ï¼Ÿ

è®¿é—® `http://localhost:8000/metrics` æŸ¥çœ‹ Prometheus æŒ‡æ ‡ã€‚

### 4. æ”¯æŒå“ªäº›è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼Ÿ

å½“å‰æ”¯æŒåŠ æƒè½®è¯¢ï¼ˆWeighted Round Robinï¼‰ï¼Œåç»­å¯æ‰©å±•æœ€å°‘è¿æ¥ç­‰ç­–ç•¥ã€‚

## æ–‡æ¡£

| æ–‡æ¡£ | è¯´æ˜ |
|------|------|
| [é‰´æƒç®¡é“è¯¦ç»†æ–‡æ¡£](docs/auth-pipeline.md) | å¤šæºé‰´æƒç®¡é“é…ç½®ã€Lua è„šæœ¬ç¤ºä¾‹ |
| [å¼€å‘æ–‡æ¡£](docs/development-guide.md) | æ¶æ„è®¾è®¡ã€æ ¸å¿ƒæ¨¡å—ã€å¼€å‘æŒ‡å—ã€API å‚è€ƒ |
| [OpenCode é›†æˆ](docs/opencode-integration.md) | ä¸ OpenCode ç­‰ AI ç¼–ç åŠ©æ‰‹é›†æˆ |
| [Docker å‘å¸ƒæŒ‡å—](docs/docker-publish-guide.md) | Docker é•œåƒæ„å»ºä¸å‘å¸ƒ |
| [æ›´æ–°æ—¥å¿—](CHANGELOG.md) | ç‰ˆæœ¬æ›´æ–°è®°å½• |

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) å¼€æºåè®®ã€‚

è¿™æ„å‘³ç€ä½ å¯ä»¥ï¼š
- âœ… è‡ªç”±ä½¿ç”¨ã€ä¿®æ”¹å’Œåˆ†å‘æœ¬è½¯ä»¶
- âœ… ç”¨äºå•†ä¸šé¡¹ç›®
- âœ… åˆ›å»ºè¡ç”Ÿä½œå“

å”¯ä¸€è¦æ±‚ï¼šä¿ç•™åŸå§‹ç‰ˆæƒå£°æ˜å’Œè®¸å¯è¯å£°æ˜ã€‚

## è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼æŸ¥çœ‹ [CONTRIBUTORS.md](CONTRIBUTORS.md) äº†è§£è´¡çŒ®è€…åå•ã€‚

### å¦‚ä½•è´¡çŒ®

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤ä¿®æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

è¯¦ç»†è´¡çŒ®æŒ‡å—è¯·å‚è€ƒ [CONTRIBUTORS.md](CONTRIBUTORS.md)ã€‚

## æ”¯æŒé¡¹ç›®

å¦‚æœ LLMProxy å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ï¼š

- â­ ç»™é¡¹ç›®ç‚¹ä¸ª Star
- ğŸ› æŠ¥å‘Š Bug æˆ–æå‡ºæ”¹è¿›å»ºè®®
- ğŸ“ æ”¹è¿›æ–‡æ¡£æˆ–æ·»åŠ ç¤ºä¾‹
- ğŸ’¬ åœ¨ç¤¾åŒºä¸­åˆ†äº«ä½ çš„ä½¿ç”¨ç»éªŒ
- ğŸ”— åœ¨ä½ çš„é¡¹ç›®ä¸­æ·»åŠ  "Powered by LLMProxy" å¾½ç« ï¼š

```markdown
[![Powered by LLMProxy](https://img.shields.io/badge/Powered%20by-LLMProxy-blue)](https://github.com/aiyuekuang/LLMProxy)
```

## è”ç³»æ–¹å¼

- ğŸ“§ Issues: [GitHub Issues](https://github.com/aiyuekuang/LLMProxy/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/aiyuekuang/LLMProxy/discussions)
