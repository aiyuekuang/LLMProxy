# Demo 配置 - 使用 Ollama 作为后端

server:
  listen: ":8000"

backends:
  - name: ollama
    url: "http://ollama:11434"
    weight: 5

# 用量上报
usage:
  enabled: true
  reporters:
    - name: webhook
      type: webhook
      enabled: true
      webhook:
        url: "http://webhook-receiver:3001/llm-usage"
        timeout: 1s
        retry: 2

health_check:
  enabled: true
  interval: 10s
  path: /api/tags
